{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a character level Fuel dataset from text file\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:test\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import codecs\n",
    "import subprocess\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.debug(\"test\")\n",
    "\n",
    "import numpy as np\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from toolz import merge\n",
    "import pandas as pd\n",
    "from six import add_metaclass\n",
    "from picklable_itertools.extras import equizip\n",
    "from blocks.bricks.recurrent import (GatedRecurrent, Bidirectional)\n",
    "from blocks.initialization import IsotropicGaussian, Constant, Orthogonal\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "from blocks.bricks import Initializable\n",
    "from blocks.bricks.base import application, Brick, lazy\n",
    "from blocks.bricks import Tanh, Linear, MLP\n",
    "from blocks.bricks.lookup import LookupTable\n",
    "from blocks.bricks.parallel import Fork\n",
    "from blocks.utils import (shared_floatx_nans, dict_union)\n",
    "from blocks.roles import add_role, WEIGHT\n",
    "\n",
    "\n",
    "from fuel.datasets import TextFile\n",
    "from fuel.schemes import ConstantScheme\n",
    "from fuel.streams import DataStream\n",
    "from fuel.transformers import (\n",
    "    Merge, Batch, Filter, Padding, SortMapping, Unpack, Mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path to your training data\n",
    "TRAINING_DATASET = '/home/chris/projects/machine_learning/dcu-character-lms/data/paul_graham_essays.txt'\n",
    "\n",
    "UNKNOWN_TOKEN = '|'\n",
    "EOS_TOKEN = '`'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_symbols = set()\n",
    "\n",
    "y_data_temp_file = 'temp_y.txt'\n",
    "\n",
    "# make our dictionaries, and write a temporary file for the \n",
    "with codecs.open(TRAINING_DATASET, encoding='utf8') as inp:\n",
    "    with codecs.open(y_data_temp_file, 'wb', encoding='utf8') as y_out:\n",
    "        for l in inp.read().strip().split('\\n'):\n",
    "            all_symbols.update(l)\n",
    "            y_seq = l[1:] + EOS_TOKEN + '\\n'\n",
    "            assert len(l) == len(y_seq)-1\n",
    "\n",
    "            y_out.write(''.join(y_seq))\n",
    "        \n",
    "        \n",
    "# add an unknown token in case we observe a new character at prediction time\n",
    "all_symbols.update([UNKNOWN_TOKEN, EOS_TOKEN])\n",
    "        \n",
    "len(all_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word2idx = {v:k for k,v in enumerate(all_symbols)}\n",
    "idx2word = {v:k for k,v in word2idx.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X = TextFile([TRAINING_DATASET], word2idx, bos_token=None, eos_token=None,\n",
    "                   unk_token=UNKNOWN_TOKEN, level='character')\n",
    "\n",
    "train_Y = TextFile([y_data_temp_file], word2idx, bos_token=None, eos_token=None,\n",
    "                   unk_token=UNKNOWN_TOKEN, level='character')\n",
    "\n",
    "# Merge them to get x1, x2 pairs\n",
    "stream = Merge([train_X.get_example_stream(),\n",
    "                train_Y.get_example_stream()],\n",
    "                ('x', 'y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u' '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([38,\n",
       "  43,\n",
       "  0,\n",
       "  45,\n",
       "  38,\n",
       "  0,\n",
       "  41,\n",
       "  44,\n",
       "  45,\n",
       "  0,\n",
       "  32,\n",
       "  45,\n",
       "  0,\n",
       "  36,\n",
       "  38,\n",
       "  43,\n",
       "  28,\n",
       "  0,\n",
       "  27,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  24,\n",
       "  37,\n",
       "  37,\n",
       "  48,\n",
       "  8,\n",
       "  0,\n",
       "  16,\n",
       "  0,\n",
       "  36,\n",
       "  38,\n",
       "  39,\n",
       "  45,\n",
       "  33,\n",
       "  42,\n",
       "  0,\n",
       "  27,\n",
       "  28,\n",
       "  31,\n",
       "  38,\n",
       "  43,\n",
       "  28,\n",
       "  0,\n",
       "  45,\n",
       "  33,\n",
       "  28,\n",
       "  48,\n",
       "  4,\n",
       "  43,\n",
       "  28,\n",
       "  0,\n",
       "  38,\n",
       "  44,\n",
       "  45,\n",
       "  0,\n",
       "  38,\n",
       "  31,\n",
       "  0,\n",
       "  27,\n",
       "  44,\n",
       "  42,\n",
       "  32,\n",
       "  39,\n",
       "  28,\n",
       "  42,\n",
       "  42],\n",
       " [43,\n",
       "  0,\n",
       "  45,\n",
       "  38,\n",
       "  0,\n",
       "  41,\n",
       "  44,\n",
       "  45,\n",
       "  0,\n",
       "  32,\n",
       "  45,\n",
       "  0,\n",
       "  36,\n",
       "  38,\n",
       "  43,\n",
       "  28,\n",
       "  0,\n",
       "  27,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  24,\n",
       "  37,\n",
       "  37,\n",
       "  48,\n",
       "  8,\n",
       "  0,\n",
       "  16,\n",
       "  0,\n",
       "  36,\n",
       "  38,\n",
       "  39,\n",
       "  45,\n",
       "  33,\n",
       "  42,\n",
       "  0,\n",
       "  27,\n",
       "  28,\n",
       "  31,\n",
       "  38,\n",
       "  43,\n",
       "  28,\n",
       "  0,\n",
       "  45,\n",
       "  33,\n",
       "  28,\n",
       "  48,\n",
       "  4,\n",
       "  43,\n",
       "  28,\n",
       "  0,\n",
       "  38,\n",
       "  44,\n",
       "  45,\n",
       "  0,\n",
       "  38,\n",
       "  31,\n",
       "  0,\n",
       "  27,\n",
       "  44,\n",
       "  42,\n",
       "  32,\n",
       "  39,\n",
       "  28,\n",
       "  42,\n",
       "  42,\n",
       "  25])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the stream\n",
    "sample = list(stream.get_epoch_iterator())[1]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the Model\n",
    "\n",
    "class RNNLM(Initializable):\n",
    "    \"\"\"Model for character level LM\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, state_dim, output_dim, **kwargs):\n",
    "        super(BidirectionalSemanticEncoder, self).__init__(**kwargs)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.state_dim = state_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.lookup = LookupTable(name='embeddings')\n",
    "        self.transition = GatedRecurrent(activation=Tanh(), dim=state_dim)\n",
    "        \n",
    "        self.fork = Fork(\n",
    "            [name for name in self.transition.apply.sequences\n",
    "             if name != 'mask'], prototype=Linear(), name='fork')\n",
    "\n",
    "        # output layer -- this may need to be changed\n",
    "        self.output_layer = Linear(name='output_layer')\n",
    "        \n",
    "        self.children = [self.lookup, self.transition,\n",
    "                         self.fork, self.output_layer]\n",
    "\n",
    "\n",
    "    def _push_allocation_config(self):\n",
    "        self.lookup.length = self.vocab_size\n",
    "        self.lookup.dim = self.embedding_dim\n",
    "\n",
    "        self.fork.input_dim = self.embedding_dim\n",
    "        self.fork.output_dims = [self.transition.get_dim(name)\n",
    "                                     for name in self.fork.output_names]\n",
    "        \n",
    "        self.output_layer.input_dim = self.state_dim\n",
    "        self.output_layer.output_dim = self.output_dim\n",
    "\n",
    "    def cost(self, x, x_mask, y, y_mask):\n",
    "        \n",
    "        pass\n",
    "#         return cost\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
