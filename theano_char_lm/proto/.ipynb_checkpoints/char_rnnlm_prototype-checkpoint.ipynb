{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a character level Fuel dataset from text file\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:test\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import codecs\n",
    "import subprocess\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.debug(\"test\")\n",
    "\n",
    "import numpy as np\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from toolz import merge\n",
    "import pandas as pd\n",
    "from six import add_metaclass\n",
    "from picklable_itertools.extras import equizip\n",
    "from blocks.bricks.recurrent import (GatedRecurrent, Bidirectional)\n",
    "from blocks.initialization import IsotropicGaussian, Constant, Orthogonal\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "from blocks.bricks import Initializable\n",
    "from blocks.bricks.base import application, Brick, lazy\n",
    "from blocks.bricks import Tanh, Linear, MLP\n",
    "from blocks.bricks.lookup import LookupTable\n",
    "from blocks.bricks.parallel import Fork\n",
    "from blocks.utils import (shared_floatx_nans, dict_union)\n",
    "from blocks.roles import add_role, WEIGHT\n",
    "\n",
    "\n",
    "from fuel.datasets import TextFile\n",
    "from fuel.schemes import ConstantScheme\n",
    "from fuel.streams import DataStream\n",
    "from fuel.transformers import (\n",
    "    Merge, Batch, Filter, Padding, SortMapping, Unpack, Mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path to your training data\n",
    "TRAINING_DATASET = '/home/chris/projects/machine_learning/dcu-character-lms/data/paul_graham_essays.txt'\n",
    "\n",
    "UNKNOWN_TOKEN = '_UNK_'\n",
    "EOS_TOKEN = '</S>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_symbols = set()\n",
    "\n",
    "# make our dictionaries, and write a temporary file for the \n",
    "with codecs.open(TRAINING_DATASET, encoding='utf8') as inp:\n",
    "    for l in inp.read().strip().split('\\n'):\n",
    "        all_symbols.update(l)\n",
    "        y_seq = l[1:] + [EOS_TOKEN]\n",
    "        assert len(l) == len(y_seq)\n",
    "        \n",
    "# add an unknown token in case we observe a new character at prediction time\n",
    "all_symbols.update([UNKNOWN_TOKEN])\n",
    "        \n",
    "len(all_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word2idx = {v:k for k,v in enumerate(all_symbols)}\n",
    "idx2word = {v:k for k,v in word2idx.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = TextFile([TRAINING_DATASET], word2idx, bos_token=None, eos_token=None,\n",
    "                   unk_token=UNKNOWN_TOKEN)\n",
    "\n",
    "train_Y = TextFile([x2_file], vocab, bos_token=None, eos_token=None, unk_token=unk_token)\n",
    "\n",
    "# Merge them to get x1, x2 pairs\n",
    "# stream = Merge([x1_dataset.get_example_stream(),\n",
    "#                 x2_dataset.get_example_stream(),\n",
    "#                 score_dataset.get_example_stream()],\n",
    "#                 ('x1', 'x2', 'y'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
